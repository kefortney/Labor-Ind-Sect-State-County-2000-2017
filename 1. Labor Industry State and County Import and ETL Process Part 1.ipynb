{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os \n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction and Instructions\n",
    "\n",
    "These series of Jupyter notebooks were made to take the state and county labor statistics documents from the Vermont Department of Labor, clean and transform them into a Tidy format for large data analysis and conversion to geospatial datasets to be posted on the Open Data Portal. \n",
    "\n",
    "Each notebook is numbered to show the sequence of steps. For this notebook the focus is downloading and adding all the data into Vermont and County datasets with all years. The first step below is setting the year of the file you are adding, this must be changed every time to reflect the next year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "year = '2017'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "All the data below was downloaded from the Vermont Department of Labor here: http://www.vtlmi.info/indnaics.htm#mqa Below is the Year To Date table for State and County with Industry sectors. The next section can uncommented be run the very first time to automatically pull the speadsheets to your local drive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List of direct urls of excell files on the http://www.vtlmi.info/indnaics.htm#mqa site, add additional years if they are there\n",
    "urllist = [\"http://www.vtlmi.info/public/qcew/vtqcewytd_cty2017.xls\",\n",
    "           \"http://www.vtlmi.info/public/qcew/vtqcewytd_cty2016.xls\",\n",
    "           \"http://www.vtlmi.info/public/qcew/vtqcewytd_cty2015.xls\",\n",
    "           \"http://www.vtlmi.info/public/qcew/vtqcewytd_cty2014.xls\",\n",
    "           \"http://www.vtlmi.info/public/qcew/vtqcewytd_cty2013.xls\",\n",
    "           \"http://www.vtlmi.info/public/qcew/vtqcewytd_cty2012.xls\",\n",
    "           \"http://www.vtlmi.info/public/qcew/vtqcewytd_cty2011.xls\",\n",
    "           \"http://www.vtlmi.info/public/qcew/vtqcewytd_cty2010.xls\",\n",
    "           \"http://www.vtlmi.info/public/qcew/vtqcewytd_cty2009.xls\",\n",
    "           \"http://www.vtlmi.info/public/qcew/vtqcewytd_cty2008.xls\",\n",
    "           \"http://www.vtlmi.info/public/qcew/vtqcewytd_cty2007.xls\",\n",
    "           \"http://www.vtlmi.info/public/qcew/vtqcewytd_cty2006.xls\",\n",
    "           \"http://www.vtlmi.info/public/qcew/vtqcewytd_cty2005.xls\",\n",
    "           \"http://www.vtlmi.info/public/qcew/vtqcewytd_cty2004.xls\",\n",
    "           \"http://www.vtlmi.info/public/qcew/vtqcewytd_cty2003.xls\",\n",
    "           \"http://www.vtlmi.info/public/qcew/vtqcewytd_cty2002.xls\",\n",
    "           \"http://www.vtlmi.info/public/qcew/vtqcewytd_cty2001.xls\",\n",
    "           \"http://www.vtlmi.info/public/qcew/vtqcewytd_cty2000.xls\"\n",
    "          ]\n",
    "\n",
    "# This is to pull all the files\n",
    "#for x in urllist:\n",
    "#    resp = requests.get(x)\n",
    "#    output = open(x[-11:], 'wb')\n",
    "#    output.write(resp.content)\n",
    "#    output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.\\\\cty2000.xls',\n",
       " '.\\\\cty2001.xls',\n",
       " '.\\\\cty2002.xls',\n",
       " '.\\\\cty2003.xls',\n",
       " '.\\\\cty2004.xls',\n",
       " '.\\\\cty2005.xls',\n",
       " '.\\\\cty2006.xls',\n",
       " '.\\\\cty2007.xls',\n",
       " '.\\\\cty2008.xls',\n",
       " '.\\\\cty2009.xls',\n",
       " '.\\\\cty2010.xls',\n",
       " '.\\\\cty2011.xls',\n",
       " '.\\\\cty2012.xls',\n",
       " '.\\\\cty2013.xls',\n",
       " '.\\\\cty2014.xls',\n",
       " '.\\\\cty2015.xls',\n",
       " '.\\\\cty2016.xls',\n",
       " '.\\\\cty2017.xls']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lists what files are currently in the local folder\n",
    "glob.glob('./*.xls')\n",
    "doclist = glob.glob('./*.xls')\n",
    "doclist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Dataset\n",
    "\n",
    "In order to add all the years to one file a CSV for county and for state are saved to the local drive, this checks if it has already been created (which it would if it was the second or more time). If you need to restart everything, delete the local CSV files and restart at the first year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports the running dataset which the year selected will be added\n",
    "if os.path.isfile('cumllaborvt.csv'):\n",
    "    cumllaborvt = pd.read_csv(\"cumllaborvt.csv\")\n",
    "else:\n",
    "    cumllaborvt =  pd.DataFrame()\n",
    "    \n",
    "if os.path.isfile('cumllaborcnty.csv'):\n",
    "    cumllaborcnty = pd.read_csv(\"cumllaborcnty.csv\")\n",
    "else:\n",
    "    cumllaborcnty =  pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['County Areas', 'Vermont', 'Addison', 'Bennington', 'Caledonia', 'Chittenden', 'Essex', 'Franklin', 'Grand Isle', 'Lamoille', 'Orange', 'Orleans', 'Rutland', 'Washington', 'Windham', 'Windsor', 'All Other']\n"
     ]
    }
   ],
   "source": [
    "# Imports excel file and gives list of sheets\n",
    "data = pd.ExcelFile('cty'+year+'.xls')\n",
    "colList = data.sheet_names\n",
    "\n",
    "print(colList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creates a dictionary of sheet names and blank value where the data will be placed\n",
    "locations = {'Vermont':None, 'Addison':None, 'Bennington':None, 'Caledonia':None, 'Chittenden':None, \n",
    "             'Essex':None, 'Franklin':None, 'Grand Isle':None, 'Lamoille':None, 'Orange':None, 'Orleans':None,\n",
    "             'Rutland':None, 'Washington':None, 'Windham':None, 'Windsor':None, 'All Other':None}\n",
    "\n",
    "# Parses each sheet in the spreadsheet into the dictionary value\n",
    "for item in locations.keys():\n",
    "    locations[item] = data.parse(item, skiprows=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Takes the county name from the first row of each data set and adds it as a column value for all rows for when it is added together\n",
    "for item in locations.values():\n",
    "    item['County'] = item.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Takes all the data in the dictionary and appends them together as a list of dataframes\n",
    "datalist = []\n",
    "\n",
    "for item in locations.values():\n",
    "    datalist.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Appends everything together in a single large dataframe\n",
    "cumlative = pd.concat(datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug',\n",
       "       'Sep', 'Oct', 'Nov', 'Dec', 'Qtr 1', 'Qtr 2', 'Qtr 3', 'Qtr 4',\n",
       "       'Annual', 'Qtr 1.1', 'Qtr 2.1', 'Qtr 3.1', 'Qtr 4.1', 'Annual.1',\n",
       "       'Qtr 1.2', 'Qtr 2.2', 'Qtr 3.2', 'Qtr 4.2', 'Annual.2', 'Qtr 1.3',\n",
       "       'Qtr 2.3', 'Qtr 3.3', 'Qtr 4.3', 'Annual.3', 'County'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View column names before renaming them\n",
    "cumlative.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Female Employment\n",
    "\n",
    "The count of female employment stopped as of 2016. As this changes the number of columns the code below inserts NaN columns in order to append it all together successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Type', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep',\n",
       "       'Oct', 'Nov', 'Dec', 'Average Employment Qtr 1',\n",
       "       'Average Employment Qtr 2', 'Average Employment Qtr 3',\n",
       "       'Average Employment Qtr 4', 'Average Employment Annual',\n",
       "       'Total Wages Qtr 1', 'Total Wages Qtr 2', 'Total Wages Qtr 3',\n",
       "       'Total Wages Qtr 4', 'Total Wages Annual', 'Average Wage Qtr 1',\n",
       "       'Average Wage Qtr 2', 'Average Wage Qtr 3', 'Average Wage Qtr 4',\n",
       "       'Average Wage Annual', 'Number of Establishments Qtr 1',\n",
       "       'Number of Establishments Qtr 2', 'Number of Establishments Qtr 3',\n",
       "       'Number of Establishments Qtr 4', 'Number of Establishments Annual',\n",
       "       'County', 'Average Female Employment Qtr 1',\n",
       "       'Average Female Employment Qtr 2', 'Average Female Employment Qtr 3',\n",
       "       'Average Female Employment Qtr 4', 'Average Female Employment Annual'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collist1 = ['Type', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug','Sep', 'Oct', 'Nov', 'Dec', \n",
    "           'Average Employment Qtr 1', 'Average Employment Qtr 2', 'Average Employment Qtr 3', 'Average Employment Qtr 4', 'Average Employment Annual',\n",
    "           'Average Female Employment Qtr 1', 'Average Female Employment Qtr 2', 'Average Female Employment Qtr 3', 'Average Female Employment Qtr 4', 'Average Female Employment Annual',\n",
    "           'Total Wages Qtr 1', 'Total Wages Qtr 2', 'Total Wages Qtr 3', 'Total Wages Qtr 4', 'Total Wages Annual',\n",
    "           'Average Wage Qtr 1','Average Wage Qtr 2', 'Average Wage Qtr 3', 'Average Wage Qtr 4', 'Average Wage Annual',\n",
    "           'Number of Establishments Qtr 1', 'Number of Establishments Qtr 2', 'Number of Establishments Qtr 3', 'Number of Establishments Qtr 4', 'Number of Establishments Annual','County']\n",
    "\n",
    "collist2 = ['Type', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug','Sep', 'Oct', 'Nov', 'Dec', \n",
    "              'Average Employment Qtr 1', 'Average Employment Qtr 2', 'Average Employment Qtr 3', 'Average Employment Qtr 4', 'Average Employment Annual',\n",
    "              'Total Wages Qtr 1', 'Total Wages Qtr 2', 'Total Wages Qtr 3', 'Total Wages Qtr 4', 'Total Wages Annual',\n",
    "              'Average Wage Qtr 1','Average Wage Qtr 2', 'Average Wage Qtr 3', 'Average Wage Qtr 4', 'Average Wage Annual',\n",
    "              'Number of Establishments Qtr 1', 'Number of Establishments Qtr 2', 'Number of Establishments Qtr 3', 'Number of Establishments Qtr 4', 'Number of Establishments Annual','County']\n",
    "\n",
    "def changeheader(data):\n",
    "    if len(data.columns) == 39:\n",
    "        data.columns = collist1\n",
    "    elif len(data.columns) == 34:\n",
    "        data.columns = collist2\n",
    "        data['Average Female Employment Qtr 1'] = np.nan\n",
    "        data['Average Female Employment Qtr 2'] = np.nan\n",
    "        data['Average Female Employment Qtr 3'] = np.nan\n",
    "        data['Average Female Employment Qtr 4'] = np.nan\n",
    "        data['Average Female Employment Annual'] = np.nan\n",
    "\n",
    "changeheader(cumlative)\n",
    "cumlative.columns           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds the year \n",
    "cumlative['Year'] = year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes all NA rows and rows that contain footnotes or count names as these had individual rows without values\n",
    "exclude = ['nan', '(c) = data can not be released, does not meet confidentiality standards', \n",
    "           '- = zero employment, wages or establishments','na = data is not available', 'released: November 2015',\n",
    "           'Addison County', 'Vermont','Bennington County', 'Caledonia County', 'Essex County', 'Franklin County', \n",
    "           'Grand Isle County', 'Lamoille County', 'Orange County', 'Orleans County', 'Rutland County', 'Washington County',\n",
    "           'Windham County','Windsor County', 'All Other county']\n",
    "    \n",
    "cumlative = cumlative.loc[~cumlative['Type'].isin(exclude)]\n",
    "cumlative = cumlative.loc[cumlative['Type'].notnull()]\n",
    "\n",
    "# removes all leading whitespaces on the type name, indentation was used to show hierachy in the original file\n",
    "cumlative['Type'] = cumlative['Type'].str.lstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creates county only data set\n",
    "cumlativecnty = cumlative[cumlative['County'] != 'Vermont']\n",
    "\n",
    "# Creates state only data set\n",
    "cumlativevt = cumlative[cumlative['County'] == 'Vermont']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Checks if this is the first time this has been run and either creates the first dataset for saving to a csv or appends it to what is there\n",
    "if cumllaborcnty.empty:\n",
    "    cumllaborcnty = cumlativecnty\n",
    "else:\n",
    "    cumllaborcnty = cumllaborcnty.append(cumlativecnty, ignore_index=True)\n",
    "    \n",
    "if cumllaborvt.empty:\n",
    "    cumllaborvt = cumlativevt\n",
    "else:\n",
    "    cumllaborvt = cumllaborvt.append(cumlativevt, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cumllaborcnty.to_csv(\"cumllaborcnty.csv\", index=False)\n",
    "#cumllaborvt.to_csv(\"cumllaborvt.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
